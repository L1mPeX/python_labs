# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ 4

## –ö–æ–ª–ª–µ–∫—Ü–∏–∏ –∏ –º–∞—Ç—Ä–∏—Ü—ã (list/tuple/set/dict)


io_txt_to_csv.py
```python
from pathlib import Path
import csv
from typing import Iterable, Sequence

def read_text(path: str | Path, encoding: str = "utf-8") -> str:
    """
    –ü—Ä–æ—á–∏—Ç–∞—Ç—å –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞ —Å –∑–∞–¥–∞–Ω–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π (UTF-8 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
    –ï—Å–ª–∏ –Ω—É–∂–Ω–æ, —É–∫–∞–∂–∏—Ç–µ –¥—Ä—É–≥—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É, –Ω–∞–ø—Ä–∏–º–µ—Ä, encoding="cp1251"
    –ò—Å–∫–ª—é—á–µ–Ω–∏—è FileNotFoundError –∏ UnicodeDecodeError –Ω–µ –ø–æ–¥–∞–≤–ª—è—é—Ç—Å—è
    """
    p = Path(path)
    return p.read_text(encoding=encoding)

def write_csv(rows: list[tuple | list], path: str | Path,
              header: tuple[str, ...] | None = None) -> None:
    """
    –ó–∞–ø–∏—Å–∞—Ç—å —Å—Ç—Ä–æ–∫–∏ –≤ CSV-—Ñ–∞–π–ª —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º –∑–∞–ø—è—Ç–æ–π
    –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω header, –æ–Ω –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–æ–π
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—É—é –¥–ª–∏–Ω—É –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫, –∏–Ω–∞—á–µ –≤—ã–∑—ã–≤–∞–µ—Ç ValueError
    –°–æ–∑–¥–∞—ë—Ç/–ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ñ–∞–π–ª
    """
    if not rows and header is None:
        # –ü—É—Å—Ç–æ–π —Ñ–∞–π–ª
        with open(path, "w", encoding="utf-8", newline="") as f:
            pass
        return
    if rows:
        length = len(rows[0])
        for i, row in enumerate(rows):
            if len(row) != length:
                raise ValueError(f"Row {i} length {len(row)} != first row length {length}")
    p = Path(path)
    ensure_parent_dir(p)
    with p.open("w", encoding="utf-8", newline="") as f:
        writer = csv.writer(f)
        if header:
            writer.writerow(header)
        writer.writerows(rows)

def ensure_parent_dir(path: str | Path) -> None:
    """–°–æ–∑–¥–∞—Ç—å —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç"""
    p = Path(path)
    if parent := p.parent:
        parent.mkdir(parents=True, exist_ok=True)
```

text_report.py
```python
import sys
import argparse
from collections import Counter
from lib.text import normalize, tokenize, count_freq, top_n
from io_txt_to_csv import read_text, write_csv

def frequencies_from_text(text: str) -> dict[str, int]:
    tokens = tokenize(normalize(text))
    return Counter(tokens)

def sorted_word_counts(freq: dict[str, int]) -> list[tuple[str, int]]:
    return sorted(freq.items(), key=lambda kv: (-kv[1], kv[0]))

def main():
    parser = argparse.ArgumentParser(description="–°—á—ë—Ç—á–∏–∫ —á–∞—Å—Ç–æ—Ç —Å–ª–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ —Å –≤—ã–≤–æ–¥–æ–º –≤ CSV.")
    parser.add_argument("--in", dest="input_path", default="../data/input.txt",
                        help="–í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª")
    parser.add_argument("--out", dest="output_path", default="../data/report.csv",
                        help="–ü—É—Ç—å –¥–ª—è CSV –æ—Ç—á—ë—Ç–∞")
    parser.add_argument("--encoding", default="utf-8",
                        help="–ö–æ–¥–∏—Ä–æ–≤–∫–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é utf-8)")
    args = parser.parse_args()

    try:
        text = read_text(args.input_path, encoding=args.encoding)
    except FileNotFoundError:
        print(f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª {args.input_path} –Ω–µ –Ω–∞–π–¥–µ–Ω.", file=sys.stderr)
        sys.exit(1)
    except UnicodeDecodeError:
        print(f"–û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª {args.input_path} —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π {args.encoding}.", file=sys.stderr)
        sys.exit(1)

    freq = frequencies_from_text(text)
    sorted_freq = sorted_word_counts(freq)

    total_words = sum(freq.values())
    unique_words = len(freq)

    # –ó–∞–ø–∏—Å—å CSV —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
    write_csv(sorted_freq, args.output_path, header=("word", "count"))

    # –í—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å –∫—Ä–∞—Ç–∫–æ–≥–æ –æ—Ç—á—ë—Ç–∞, –≤–∫–ª—é—á–∞—è —Ç–æ–ø-5
    print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {total_words}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {unique_words}")
    print("–¢–æ–ø-5:")
    for word, count in top_n(freq, 5):
        print(f"{word}:{count}")

if __name__ == "__main__":
    main()
```

–¢–µ—Å—Ç—ã –∑–∞–ø—É—Å–∫–∞—é—Ç—Å—è —Å–∫—Ä–∏–ø—Ç–æ–º tests.sh:
```bash
#!/bin/bash
set -e

echo "–°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª data/lab04/input.txt –¥–ª—è –õ–†4..."
cat > ../data/lab04/input.txt << EOF
–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç!!! üèß üöÆ
EOF

echo "–°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª data/lab04/a.txt..."
cat > ../data/lab04/a.txt << EOF
–ü—Ä–∏–≤–µ—Ç –º–∏—Ä
EOF

echo "–°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª data/lab04/b.txt..."
cat > ../data/lab04/b.txt << EOF
–ü—Ä–∏–≤–µ—Ç, –ø—Ä–∏–≤–µ—Ç!
EOF

echo "–ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–ø—Ç –õ–†4 –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º output report.csv..."
python3 text_report.py --in ../data/lab04/input.txt --out ../data/lab04/report.csv

echo "–ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ data/lab04/report.csv..."
head -n 10 ../data/lab04/report.csv

echo "–¢–µ—Å—Ç—ã –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ."
```
![–°–∫—Ä–∏–Ω—à–æ—Ç 1](./materials/image.png)

## –õ–∏—Ü–µ–Ω–∑–∏—è <a name="license"></a>

[![License: CC BY-NC-SA 4.0](https://licensebuttons.net/l/by-nc-sa/4.0/80x15.png)](https://creativecommons.org/licenses/by-nc-sa/4.0/)
–ü—Ä–æ–µ–∫—Ç –¥–æ—Å—Ç—É–ø–µ–Ω —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º –Ω–∞ —É—Å–ª–æ–≤–∏—è—Ö [–õ–∏—Ü–µ–Ω–∑–∏–∏ CC BY-NC-SA 4.0](./LICENSE).

_–ê–≤—Ç–æ—Ä—Å–∫–∏–µ –ø—Ä–∞–≤–∞ 2025 –ê–Ω–¥—Ä–µ–π –ö–∞–∑–∞—Ä–∏–Ω_
